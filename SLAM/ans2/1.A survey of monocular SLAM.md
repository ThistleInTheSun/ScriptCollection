SLAM (同时定位与地图构建) 调研 [2020 武汉大学]

# abstract
Simultaneous Localization and Mapping (SLAM) 实现了基于自我感知的同步定位和地图构建的目的。
本文在SLAM做了概述，包括雷达SLAM、视觉SLAM、其他融合等。
对于雷达SLAM和视觉SLAM，本文阐述了传感器的基本类型和产品、开源系统的排序和历史、嵌入式深度学习、挑战和未来方向。
此外，还补充了视觉惯性里程计。
对于雷达和视觉混合的SLAM，本文强调了多传感器标定、硬件融合、数据、任务层。
本文以开放问题和前瞻性思考结束。
本文的贡献可以被总结为：本文在SLAM领域提供了一种高质量、全尺度的总览。
这对于新的研究者很友好，以便他们把握SLAM的发展，学习的很显然。
此外，对于有经验的研究者，本文可被当做字典，用来研究和发现新的有趣方向。

# 1.Introduction
SLAM是Simultaneous Localization and Mapping的缩写，他包含了两个主要任务——定位和构建地图。
这对于移动机器人来说，是个重要且开放的问题：为了精确移动，机器人必须有精确的环境地图；然而为了精确构建环境地图，移动机器人的位置感知必须精确。
这样看来，同步构建地图和定位看起来是个先到先得的问题，先有鸡还是先有蛋？

1990年，[2]首先提出使用EKF (Extended Kalman Filter, 扩展卡尔曼滤波器) 来增量估计机器人姿态的后验分布以及地标的位置。
事实上，从位置环境的未知位置开始，机器人通过在运动过程中反复观察环境特征来定位它自己的位置和姿态，然后根据它的位置构建周围环境的增量地图，以此达到同时定位和建图的目的。
定位很复杂，是近年来的热点。
定位技术依赖于成本、精度、频率、鲁棒性等环境需求，这些都可以有GPS、IMU (Inertial Measurement Unit, 惯性测量单元)、无线信号等获得。
但GPS只能在户外表现良好，IMU有累计误差。
无线信号技术，作为一种主动系统，不能很好的平衡成本和精度。
近几年，有了雷达、相机、IMU和其他感知设备，SLAM得到了迅速发展。

从基于过滤器的 SLAM 开始，基于图的 SLAM 现在占据主导地位。
该算法从 KF（卡尔曼滤波器）、EKF 和 PF（粒子滤波器）派生到基于图形的优化。
并且单线程已经被多线程所取代。
SLAM的技术也从最早的军用雏形发展到后来多传感器融合的机器人应用。
本文的结构可以被总结为：
章节2, 介绍雷达SLAM，包括雷达传感器、开源雷达SLAM系统、雷达中的深度学习以及挑战和未来方向。
章节3, 介绍视觉SLAM，包括相机传感器、不同密度的SLAM开源视觉系统、视觉惯性里程SLAM、视觉SLAM中的深度学习和未来展望。
章节4，介绍雷达SLAM和视觉SLAM的融合。
最后，本文确定了几个未来研究的方向，为SLAM的新研究人员提供高质量和全面的用户指南。

# 2.雷达SLAM
在1991年，[1]使用多个伺服安装的声呐传感器和EKF滤波器为机器人配备SLAM系统。
从声纳传感器开始，激光雷达的诞生让SLAM系统更加可靠和健壮。

## A.雷达传感器
雷达传感器可以被分为2D雷达和3D雷达，由雷达光束的数量决定。
在生产工艺方面，雷达可以被分为机械雷达、混合固态雷达——例如MEMS（微机电）、和固态雷达。
相控阵和闪光技术可生产固态激光雷达。

+ Velodyne：在机械雷达中，有VLP-16、HDL-32E和HDL-64E。在混合固态雷达中，有Ultra puck with 32E。
+ SLAMTEC：它拥有低成本的激光雷达和机器人平台，如 RPLIDAR A1、A2 和 R3。
+ Quster：它有从16到128通道的机械雷达。
+ Quanergy：S3是全球首发的固态激光雷达，M8是机械式激光雷达。 S3-QI 是微型固态激光雷达。
+ Ibeo：它在机械激光雷达中有 Lux 4L 和 Lux 8L。 与法雷奥合作，发布了名为Scala的混合固态激光雷达。

在这个趋势下，小型化、轻量化的固态激光雷达将占领市场并满足大部分应用。
其他雷达公司包括但不仅限于sick, Hokuyo, HESAI, RoboSense, LeddarTech, ISureStar, benewake, Livox, Innovusion, Innoviz, Trimble, Leishen Intelligent System.

## B.雷达SLAM系统
雷达SLAM在理论上和技术上都是可靠的。[6]阐述了关于如何基于概率，用2D雷达同步定位和建图的数学理论。
更进一步地，[7]对2D激光雷达SLAM系统进行调查。

### 1）2D SLAM
+ Gmapping：它是基于RBPF（Rao-Blackwellization Particle Filter 粒子过滤器）方法的机器人中使用最多的SLAM包。它增加了扫描匹配方法来估计位置[8][6]。 它是基于FastSLAM[9][10]的带有Grid地图的改进版本。
+ HectorSlam：它结合了 2D SLAM 系统和 3D 导航与扫描匹配技术和惯性传感系统[11]。
+ KartoSLAM：它是一个基于图的 SLAM 系统[12]。 • LagoSLAM：它的基础是基于图的SLAM，它是非线性非凸成本函数的最小化[13]。
+ CoreSLAm：这是一种以最小的性能损失来理解的算法[14]。
+ Cartographer：它是来自谷歌的SLAM 系统[15]。它采用子图和闭环来实现更好的产品等级性能。该算法可以跨多个平台和传感器配置提供 2D 和 3D SLAM。

### 2) 3D SLAM
+ Loam：它是一种使用 3D 激光雷达 [16] 进行状态估计和映射的实时方法。它还具有来回旋转版本和连续扫描 2D 激光雷达版本。
+ Lego-Loam：它从 Velodyne VLP-16 激光雷达（水平放置）和可选的 IMU 数据中获取点云作为输入。系统实时输出 6D 姿态估计，并具有全局优化和闭环[17]。
+ Cartographer：它支持2D 和3D SLAM[15]。
+ IMLS-SLAM：它提出了一种新的低漂移 SLAM 算法，仅基于基于扫描模型匹配框架的 3D LiDAR 数据 [18]。

### 3）使用激光雷达 SLAM 进行深度学习
+ Feature & Detection：
PointNetVLAD[9] 提供了一种端到端的训练和推理，从3D点云数据中抽取全局描述，以解决基于点云的地点识别检索。
VoxelNet[20] 是一个通用的3D检测网络，能在单阶段、端到端训练的深度学习中统一特征提取和bbox预测。
其他网络见BirdNet [21]。
LMNet[22] 描述了一种有效的单阶段深度卷积神经网络，去检测目标、输出对象映射和每个点的bbox偏移值。
PIXOR[23] 是一个无需提议的单阶段检测器，它可以输出从像素级神经网络预测解码的定向 3D 对象估计。
Yolo3D[24] 基于 2D 透视图像空间中 oneshot 回归元架构的成功，并将其扩展为从 LiDAR 点云生成定向 3D 对象边界框。
PointCNN[25] 提议从输入点学习 X 变换。X变换通过典型卷积运算操作的逐元素乘积和求和运算来应用。
MV3D[26] 是感知融合框架，它用雷达点云和RGB图像作为输入，预测定向的3D检测框。
PU-GAN[27] 基于GAN提出了一个新的点云上采样网络。
其他类似工作可以在CVPR2018的[28]这篇最佳论文里看到。

+ Recognition & Segmentation：事实上，3D点云分割模型可以被分为基于边缘的、区域增长的、模型拟合的、混合方法的、机器学习应用、和深度学习[29]。本文重点关注基于深度学习的模型。
PointNet[30] 设计了一种新型神经网络，它可以直接输入点云数据，它有一个分类、分割和感知分析方法。
PointNet++：学习了分层特征

+ Localization

## C.挑战与展望